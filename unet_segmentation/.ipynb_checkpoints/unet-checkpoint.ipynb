{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbad1bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-02T14:29:56.140236Z",
     "start_time": "2022-07-02T14:29:55.326156Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from do_conv import DOConv2d\n",
    "from aspp import _ASPP\n",
    "\n",
    "# 基本卷积块\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(Conv, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(C_in, C_out, 3, 1, 1),\n",
    "            nn.BatchNorm2d(C_out),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(C_out, C_out, 3, 1, 1),\n",
    "            nn.BatchNorm2d(C_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class DOConv(nn.Module):\n",
    "    def __init__(self, C_in, C_out):\n",
    "        super(DOConv, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            \n",
    "            DOConv2d(C_in, C_out, 3, 9, 1, 1),\n",
    "            nn.BatchNorm2d(C_out),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            DOConv2d(C_out, C_out, 3, 9, 1, 1),\n",
    "            nn.BatchNorm2d(C_out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "# 下采样模块\n",
    "class DownSampling(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super(DownSampling, self).__init__()\n",
    "        self.Down = nn.Sequential(\n",
    "            # 使用卷积进行2倍的下采样，通道数不变\n",
    "            nn.Conv2d(C, C, 3, 2, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Down(x)\n",
    "\n",
    "# 上采样模块\n",
    "class UpSampling(nn.Module):\n",
    "\n",
    "    def __init__(self, C):\n",
    "        super(UpSampling, self).__init__()\n",
    "        # 特征图大小扩大2倍，通道数减半\n",
    "        self.Up = nn.Conv2d(C, C // 2, 1, 1)\n",
    "\n",
    "    def forward(self, x, r):\n",
    "        # 使用邻近插值进行下采样\n",
    "        up = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "        x = self.Up(up)\n",
    "        # 拼接，当前上采样的，和之前下采样过程中的\n",
    "        return torch.cat((x, r), 1)\n",
    "\n",
    "\n",
    "# 主干网络\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # 4次下采样\n",
    "        self.C1 = Conv(1, 64)\n",
    "        self.D1 = DownSampling(64)\n",
    "        self.C2 = Conv(64, 128)\n",
    "        self.D2 = DownSampling(128)\n",
    "        self.C3 = Conv(128, 256)\n",
    "        self.D3 = DownSampling(256)\n",
    "        self.C4 = Conv(256, 512)\n",
    "        self.D4 = DownSampling(512)\n",
    "        self.aspp = _ASPP(512, 1024, [6, 12, 18, 24])\n",
    "\n",
    "        # 4次上采样\n",
    "        self.U1 = UpSampling(1024)\n",
    "        self.C5 = DOConv(1024, 512)\n",
    "        self.U2 = UpSampling(512)\n",
    "        self.C6 = DOConv(512, 256)\n",
    "        self.U3 = UpSampling(256)\n",
    "        self.C7 = DOConv(256, 128)\n",
    "        self.U4 = UpSampling(128)\n",
    "        self.C8 = DOConv(128, 64)\n",
    "\n",
    "        self.Th = nn.Sigmoid()\n",
    "        self.pred = DOConv2d(64, 3, 3, 9, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 下采样部分\n",
    "        R1 = self.C1(x)\n",
    "        R2 = self.C2(self.D1(R1))\n",
    "        R3 = self.C3(self.D2(R2))\n",
    "        R4 = self.C4(self.D3(R3))\n",
    "        Y1 = self.aspp(self.D4(R4))\n",
    "\n",
    "        # 上采样部分\n",
    "        # 上采样的时候需要拼接起来\n",
    "        O1 = self.C5(self.U1(Y1, R4))\n",
    "        O2 = self.C6(self.U2(O1, R3))\n",
    "        O3 = self.C7(self.U3(O2, R2))\n",
    "        O4 = self.C8(self.U4(O3, R1))\n",
    "\n",
    "        # 输出预测，这里大小跟输入是一致的\n",
    "        # 可以把下采样时的中间抠出来再进行拼接，这样修改后输出就会更小\n",
    "        return self.Th(self.pred(O4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4c5d6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-02T14:29:58.088436Z",
     "start_time": "2022-07-02T14:29:56.185237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    a = torch.randn(2, 1, 256, 256)\n",
    "    net = UNet()\n",
    "    print(net(a).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3caf791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
